{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T10:46:26.110348Z",
     "iopub.status.busy": "2025-09-14T10:46:26.109606Z",
     "iopub.status.idle": "2025-09-14T10:46:26.356301Z",
     "shell.execute_reply": "2025-09-14T10:46:26.353660Z",
     "shell.execute_reply.started": "2025-09-14T10:46:26.110299Z"
    }
   },
   "outputs": [],
   "source": [
    "# \"magic commands\" to enable autoreload of your imported packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to load all 9 `.csv` files into 9 `pandas.DataFrame`s in a single dict named `data` where:\n",
    "- each **key** is the **cleaned name** of the csv file\n",
    "- each **value** is the **DataFrame** created from the csv\n",
    "\n",
    "```python\n",
    "data = { \n",
    "    'sellers': DataFrame1,\n",
    "    'orders': DataFrame2,\n",
    "    ...\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create the variable `csv_path`, which stores the path to your `\"csv\" folder` as a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When calling `pd.read_csv(csv_path)`, `csv_path` can be absolute or relative:\n",
    "    - A **`relative path`** can start with `.` or `..`, it is always computed with respect to your current working directory \n",
    "        - *Reminder: you can use `!pwd` in your notebook or `pwd` in your terminal to know where you are located*\n",
    "    - An **`absolute path`** starts with `/` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T10:49:15.123941Z",
     "iopub.status.busy": "2025-09-14T10:49:15.123138Z",
     "iopub.status.idle": "2025-09-14T10:49:15.143014Z",
     "shell.execute_reply": "2025-09-14T10:49:15.141688Z",
     "shell.execute_reply.started": "2025-09-14T10:49:15.123876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/emtenan/code/Emtenan12/04-Decision-Science/01-Project-Setup/data-data-preparation'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check your current working directory using `os.getcwd()` below\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☝️ `getcwd` a.k.a `get current working directory` refers to the absolute path _from which this notebook is being executed_\n",
    "\n",
    "Create a relative `csv_path` from your current folder to the csv folder.\n",
    "\n",
    "Try to use [`os.path.join`](https://docs.python.org/3/library/os.path.html), which replaces both:\n",
    "* Linux/MacOS syntax (e.g. `../folder_name`) \n",
    "* and Windows syntax (e.g. `..\\\\folder_name`) \n",
    "\n",
    "and is therefore more robust!\n",
    "\n",
    "Have a look at the image below to see how you can get from your current location to the csv folder.\n",
    "<img alt=\"Folder structure of olist with relative path\" src=\"https://wagon-public-datasets.s3.amazonaws.com/04-Decision-Science/01-Project-Setup/folders-olist-data-relative.png\" width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T10:53:09.770742Z",
     "iopub.status.busy": "2025-09-14T10:53:09.769909Z",
     "iopub.status.idle": "2025-09-14T10:53:09.812190Z",
     "shell.execute_reply": "2025-09-14T10:53:09.810621Z",
     "shell.execute_reply.started": "2025-09-14T10:53:09.770676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /home/emtenan/code/Emtenan12/04-Decision-Science/01-Project-Setup/data-data-preparation\n",
      "\n",
      "Files/folders in current directory:\n",
      "  tests\n",
      "  .git\n",
      "  .ipynb_checkpoints\n",
      "  .gitignore\n",
      "  Makefile\n",
      "  data_preparation.ipynb\n",
      "  README.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check current working directory\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "\n",
    "# List what's in the current directory\n",
    "print(\"\\nFiles/folders in current directory:\")\n",
    "for item in os.listdir('.'):\n",
    "    print(f\"  {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T10:59:29.535802Z",
     "iopub.status.busy": "2025-09-14T10:59:29.535308Z",
     "iopub.status.idle": "2025-09-14T10:59:29.551237Z",
     "shell.execute_reply": "2025-09-14T10:59:29.550306Z",
     "shell.execute_reply.started": "2025-09-14T10:59:29.535774Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV path: ../data-context-and-setup/data/csv\n"
     ]
    }
   ],
   "source": [
    "csv_path = os.path.join(\"..\", \"data-context-and-setup\", \"data\", \"csv\")\n",
    "print(\"CSV path:\", csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T10:54:50.106314Z",
     "iopub.status.busy": "2025-09-14T10:54:50.105876Z",
     "iopub.status.idle": "2025-09-14T10:54:50.147889Z",
     "shell.execute_reply": "2025-09-14T10:54:50.146741Z",
     "shell.execute_reply.started": "2025-09-14T10:54:50.106285Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seller_id</th>\n",
       "      <th>seller_zip_code_prefix</th>\n",
       "      <th>seller_city</th>\n",
       "      <th>seller_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3442f8959a84dea7ee197c632cb2df15</td>\n",
       "      <td>13023</td>\n",
       "      <td>campinas</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d1b65fc7debc3361ea86b5f14c68d2e2</td>\n",
       "      <td>13844</td>\n",
       "      <td>mogi guacu</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ce3ad9de960102d0677a81f5d0bb7b2d</td>\n",
       "      <td>20031</td>\n",
       "      <td>rio de janeiro</td>\n",
       "      <td>RJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c0f3eea2e14555b6faeea3dd58c1b1c3</td>\n",
       "      <td>4195</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51a04a8a6bdcb23deccc82b0b80742cf</td>\n",
       "      <td>12914</td>\n",
       "      <td>braganca paulista</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          seller_id  seller_zip_code_prefix  \\\n",
       "0  3442f8959a84dea7ee197c632cb2df15                   13023   \n",
       "1  d1b65fc7debc3361ea86b5f14c68d2e2                   13844   \n",
       "2  ce3ad9de960102d0677a81f5d0bb7b2d                   20031   \n",
       "3  c0f3eea2e14555b6faeea3dd58c1b1c3                    4195   \n",
       "4  51a04a8a6bdcb23deccc82b0b80742cf                   12914   \n",
       "\n",
       "         seller_city seller_state  \n",
       "0           campinas           SP  \n",
       "1         mogi guacu           SP  \n",
       "2     rio de janeiro           RJ  \n",
       "3          sao paulo           SP  \n",
       "4  braganca paulista           SP  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your code below\n",
    "import pandas as pd\n",
    "pd.read_csv(os.path.join(csv_path, 'olist_sellers_dataset.csv')).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create the list `file_names` containing all csv file names in the csv directory\n",
    "\n",
    "- It should look like this `file_names = ['olist_sellers_dataset.csv', ....]`\n",
    "- You can use `os.listdir()`\n",
    "- Make sure it only lists csv files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T11:01:00.441259Z",
     "iopub.status.busy": "2025-09-14T11:01:00.440948Z",
     "iopub.status.idle": "2025-09-14T11:01:00.455845Z",
     "shell.execute_reply": "2025-09-14T11:01:00.454819Z",
     "shell.execute_reply.started": "2025-09-14T11:01:00.441236Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files found: ['olist_order_items_dataset.csv', 'olist_sellers_dataset.csv', 'olist_order_payments_dataset.csv', 'olist_order_reviews_dataset.csv', 'olist_customers_dataset.csv', 'olist_orders_dataset.csv', 'olist_products_dataset.csv', 'olist_geolocation_dataset.csv', 'product_category_name_translation.csv']\n"
     ]
    }
   ],
   "source": [
    "file_names = [f for f in os.listdir(csv_path) if f.endswith('.csv')]\n",
    "print(\"CSV files found:\", file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Create the list of dict key `key_names` \n",
    "Starting from file_names and:\n",
    "- Removing its suffix \".csv\" when it exists\n",
    "- Removing its suffix \"_dataset.csv\" when it exists\n",
    "- Removing its prefix \"olist_\" when it exists\n",
    "\n",
    "<details>\n",
    "    <summary>- Hint - </summary>\n",
    "\n",
    "- `.replace()`\n",
    "    \n",
    "- `str` ings are iterables you can slice with [ ]\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T11:03:10.323450Z",
     "iopub.status.busy": "2025-09-14T11:03:10.322694Z",
     "iopub.status.idle": "2025-09-14T11:03:10.350856Z",
     "shell.execute_reply": "2025-09-14T11:03:10.349288Z",
     "shell.execute_reply.started": "2025-09-14T11:03:10.323388Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key names: ['order_items', 'sellers', 'order_payments', 'order_reviews', 'customers', 'orders', 'products', 'geolocation', 'product_category_name_translation']\n"
     ]
    }
   ],
   "source": [
    "key_names = []\n",
    "for file_name in file_names:\n",
    "    key = file_name.replace('.csv', '').replace('_dataset', '')\n",
    "    if key.startswith('olist_'):\n",
    "        key = key[6:]\n",
    "    key_names.append(key)\n",
    "print(\"Key names:\", key_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Construct the dictionary `data`\n",
    "\n",
    "```python\n",
    "data = { \n",
    "    'sellers': DataFrame1,\n",
    "    'orders': DataFrame2,\n",
    "    'order_items': DataFrame3,\n",
    "    ...\n",
    "    }\n",
    "```\n",
    "Where `DataFrame1`, `DataFrame2`, ... should be actual `pandas.DataFrame`s! Not strings containing the file path to the csv files\n",
    "\n",
    "<details>\n",
    "    <summary>▸ Hint</summary>\n",
    "\n",
    "The `zip()` method is very useful to iterate over two lists\n",
    "```python\n",
    "for (x, y) in zip(['a','b','c'], [1,2,3]):\n",
    "    print(x,y)\n",
    "\n",
    "# returns ('a', 1), ('b', 2), ('c', 3)\n",
    "    \n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T11:13:32.225707Z",
     "iopub.status.busy": "2025-09-14T11:13:32.225050Z",
     "iopub.status.idle": "2025-09-14T11:13:33.923278Z",
     "shell.execute_reply": "2025-09-14T11:13:33.922263Z",
     "shell.execute_reply.started": "2025-09-14T11:13:32.225658Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded order_items: (112650, 7)\n",
      "Loaded sellers: (3095, 4)\n",
      "Loaded order_payments: (103886, 5)\n",
      "Loaded order_reviews: (99224, 7)\n",
      "Loaded customers: (99441, 5)\n",
      "Loaded orders: (99441, 8)\n",
      "Loaded products: (32951, 9)\n",
      "Loaded geolocation: (1000163, 5)\n",
      "Loaded product_category_name_translation: (71, 2)\n",
      "\n",
      "Data dictionary has 9 DataFrames\n",
      "Keys: ['order_items', 'sellers', 'order_payments', 'order_reviews', 'customers', 'orders', 'products', 'geolocation', 'product_category_name_translation']\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for key_name, file_name in zip(key_names, file_names):\n",
    "    file_path = os.path.join(csv_path, file_name)\n",
    "    data[key_name] = pd.read_csv(file_path)\n",
    "    print(f\"Loaded {key_name}: {data[key_name].shape}\")\n",
    "\n",
    "print(f\"\\nData dictionary has {len(data)} DataFrames\")\n",
    "print(\"Keys:\", list(data.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Implement the method `get_data()` in `olist/data.py`\n",
    "\n",
    "Time to move our logic from the notebook into our `.py` files. This will allow us to easily load the data in the new notebooks we'll create througout this module. \n",
    "\n",
    "Go and open the `olist/data.py` file in the previous challenge's folder, and start moving the code you have written in this notebook to the `get_data()` method. Along the way you will need to make some changes (read further 👇 for some hints).\n",
    "\n",
    "It should return the dictionary `data` upon calling it as per below\n",
    "\n",
    "```python\n",
    "from olist.data import Olist\n",
    "Olist().get_data()\n",
    "```\n",
    "- Take time to understand what happens when `Olist().get_data()` is called\n",
    "- Your method `get_data()` needs to be callable from various places (e.g your Terminal, this notebook, another notebook located elsewhere, etc...)\n",
    "- You can't use a relative path this time as the current working directory `os.getcwd()` depends on where you run the code in the first place\n",
    "- You also can't use a _hardcoded_ absolute path, because that won't work on someone else's system.\n",
    "- So we will have to let Python create the path for us, starting from `__file__`, which will give us the absolute location of our `data.py` file. Once we know that, we can construct the path to our csv folder again. Explore the image below to see how that works.\n",
    "   <img alt=\"Folder structure of olist\" src=\"https://wagon-public-datasets.s3.amazonaws.com/04-Decision-Science/01-Project-Setup/folders-olist-data.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T11:25:37.789637Z",
     "iopub.status.busy": "2025-09-14T11:25:37.789322Z",
     "iopub.status.idle": "2025-09-14T11:25:40.900099Z",
     "shell.execute_reply": "2025-09-14T11:25:40.898880Z",
     "shell.execute_reply.started": "2025-09-14T11:25:37.789613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.9, pytest-8.3.4, pluggy-1.5.0 -- /home/emtenan/.pyenv/versions/3.12.9/envs/lewagon/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/emtenan/code/Emtenan12/04-Decision-Science/01-Project-Setup/data-data-preparation/tests\n",
      "plugins: typeguard-4.4.2, anyio-4.10.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 4 items\n",
      "\n",
      "test_get_data.py::TestGetData::test_columns \u001b[32mPASSED\u001b[0m\u001b[32m                       [ 25%]\u001b[0m\n",
      "test_get_data.py::TestGetData::test_keys \u001b[32mPASSED\u001b[0m\u001b[32m                          [ 50%]\u001b[0m\n",
      "test_get_data.py::TestGetData::test_len \u001b[32mPASSED\u001b[0m\u001b[32m                           [ 75%]\u001b[0m\n",
      "test_get_data.py::TestGetData::test_using_dunder_file \u001b[32mPASSED\u001b[0m\u001b[32m             [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 0.02s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "💯 You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/get_data.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed get_data step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "from olist.data import Olist\n",
    "data = Olist().get_data()\n",
    "result = ChallengeResult('get_data',\n",
    "    keys_len=len(data),\n",
    "    keys=sorted(list(data.keys())),\n",
    "    columns=sorted(list(data['sellers'].columns)),\n",
    "    vars_used=Olist.get_data.__code__.co_names\n",
    "    )\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T11:27:29.494326Z",
     "iopub.status.busy": "2025-09-14T11:27:29.493831Z",
     "iopub.status.idle": "2025-09-14T11:27:31.302516Z",
     "shell.execute_reply": "2025-09-14T11:27:31.301240Z",
     "shell.execute_reply.started": "2025-09-14T11:27:29.494289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seller_id</th>\n",
       "      <th>seller_zip_code_prefix</th>\n",
       "      <th>seller_city</th>\n",
       "      <th>seller_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3442f8959a84dea7ee197c632cb2df15</td>\n",
       "      <td>13023</td>\n",
       "      <td>campinas</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d1b65fc7debc3361ea86b5f14c68d2e2</td>\n",
       "      <td>13844</td>\n",
       "      <td>mogi guacu</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ce3ad9de960102d0677a81f5d0bb7b2d</td>\n",
       "      <td>20031</td>\n",
       "      <td>rio de janeiro</td>\n",
       "      <td>RJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c0f3eea2e14555b6faeea3dd58c1b1c3</td>\n",
       "      <td>4195</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51a04a8a6bdcb23deccc82b0b80742cf</td>\n",
       "      <td>12914</td>\n",
       "      <td>braganca paulista</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          seller_id  seller_zip_code_prefix  \\\n",
       "0  3442f8959a84dea7ee197c632cb2df15                   13023   \n",
       "1  d1b65fc7debc3361ea86b5f14c68d2e2                   13844   \n",
       "2  ce3ad9de960102d0677a81f5d0bb7b2d                   20031   \n",
       "3  c0f3eea2e14555b6faeea3dd58c1b1c3                    4195   \n",
       "4  51a04a8a6bdcb23deccc82b0b80742cf                   12914   \n",
       "\n",
       "         seller_city seller_state  \n",
       "0           campinas           SP  \n",
       "1         mogi guacu           SP  \n",
       "2     rio de janeiro           RJ  \n",
       "3          sao paulo           SP  \n",
       "4  braganca paulista           SP  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from olist.data import Olist\n",
    "Olist().get_data()['sellers'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓This piece of code needs to work from anywhere on your machine, not only in this notebook.\n",
    "- Open a new terminal\n",
    "- Go to your home folder `cd`\n",
    "- Launch an `ipython` session\n",
    "- Test the two lines of code above 👆"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🏁 Congratulations !\n",
    "\n",
    "💾 Don't forget to commit & push: \n",
    "* this `data_preparation.ipynb` notebook\n",
    "* as well as `data.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
